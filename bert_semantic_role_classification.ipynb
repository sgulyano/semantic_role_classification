{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81111182-0ea5-4be3-bd08-e8f34ac5003f",
   "metadata": {},
   "source": [
    "# ทำ Semantic Role Classification ภาษาไทย โดยใช้ Transformers Model จาก Hugging Face\n",
    "\n",
    "สร้าง Custom Dataset Loading Script\n",
    "- https://mageswaran1989.medium.com/how-to-build-custom-ner-huggingface-dataset-for-receipts-and-train-with-huggingface-transformers-6c954b84473c\n",
    "- https://huggingface.co/docs/datasets/dataset_script.html#download-data-files-and-organize-splits\n",
    "\n",
    "การใช้ Transformers Model จาก Hugging Face\n",
    "- https://medium.com/super-ai-engineer/ทำ-ner-ภาษาไทย-โดยใช้-transformers-model-จาก-huggingface-130c7a201d5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8237c3-bd4f-42d4-9181-6fedfce42628",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = f'./bert/'\n",
    "# MODEL_NAME = \"semrole_bert\"\n",
    "# CONFIG_NAME = 'std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac570743-fcca-4211-9a02-1f2bddd2a86a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 14:26:34.250059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv0/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  cv0\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_cv0\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c3f64bbf7448f9bfc4e1a94e092de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1790\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 448\n",
      "    })\n",
      "})\n",
      "Sample  :  ['เลี้ยง', 'ต่อไป', 'จนกระทั่ง', 'ปลา', 'สามารถ', 'กิน', 'ลูกน้ำ', 'ได้']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv0/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-fadc06b8b321889e.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv0/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-2a45f8a20cf761bf.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n",
      "\n",
      "Trained Model exists, Load model from ./bert/bert_cv0.\n",
      "Load Trained Model from ./bert/bert_cv0 completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 448\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of validation data started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of validation data completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv1/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': {'precision': 0.40181268882175225, 'recall': 0.48246674727932287, 'f1': 0.43846153846153846, 'number': 827}, 'anner': {'precision': 0.4, 'recall': 0.08, 'f1': 0.13333333333333333, 'number': 25}, 'ccompanyment': {'precision': 0.037037037037037035, 'recall': 0.1111111111111111, 'f1': 0.05555555555555555, 'number': 9}, 'easure': {'precision': 0.22950819672131148, 'recall': 0.2916666666666667, 'f1': 0.25688073394495414, 'number': 48}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 35}, 'erb': {'precision': 0.6594059405940594, 'recall': 0.738359201773836, 'f1': 0.696652719665272, 'number': 451}, 'gent': {'precision': 0.308411214953271, 'recall': 0.4230769230769231, 'f1': 0.3567567567567567, 'number': 78}, 'ime': {'precision': 0.2222222222222222, 'recall': 0.26666666666666666, 'f1': 0.2424242424242424, 'number': 45}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}, 'ocation': {'precision': 0.2692307692307692, 'recall': 0.3783783783783784, 'f1': 0.3146067415730337, 'number': 74}, 'xperiencer': {'precision': 0.4835164835164835, 'recall': 0.4835164835164835, 'f1': 0.4835164835164835, 'number': 455}, 'overall_precision': 0.4508870618779749, 'overall_recall': 0.5070559610705596, 'overall_f1': 0.4773247824095282, 'overall_accuracy': 0.7084041688225294}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Accompanyment     0.7500    0.3158    0.4444        76\n",
      "        Agent     0.5397    0.4474    0.4892       152\n",
      "   Benefactor     0.0000    0.0000    0.0000         9\n",
      "  Experiencer     0.4355    0.4655    0.4500       116\n",
      "   Instrument     0.0000    0.0000    0.0000        16\n",
      "     Location     0.4794    0.5924    0.5299       157\n",
      "       Manner     0.9444    0.2000    0.3301        85\n",
      "      Measure     0.6175    0.6568    0.6366       236\n",
      "       Object     0.7029    0.6795    0.6910       961\n",
      "         Time     0.5917    0.6536    0.6211       153\n",
      "\n",
      "    micro avg     0.6316    0.5936    0.6120      1961\n",
      "    macro avg     0.5061    0.4011    0.4192      1961\n",
      " weighted avg     0.6409    0.5936    0.6022      1961\n",
      "  samples avg     0.2500    0.2500    0.2500      1961\n",
      "\n",
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  cv1\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_cv1\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d717b0f0bb4ca4b2841d926c982f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1790\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 448\n",
      "    })\n",
      "})\n",
      "Sample  :  ['จิ่งหรีด', 'มัก', 'กัด', 'กิน', 'ต้นกล้า', 'พืช', '_', 'ใบ', 'ของ', 'พืช', '_', 'ส่วน', 'อ่อน', 'เป็น', 'อาหาร']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/vocab.txt from cache at /home/yoyo/.cache/huggingface/transformers/2c236d2bea3780922dffc22e3b3149292a1a9a9b1b7d3a150564cab2e141c43d.9bc9bc72e9459be65d9c850352dbf9415c2a73580d3c52ad2356af3657bafc66\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer_config.json from cache at /home/yoyo/.cache/huggingface/transformers/f321b63387f2d3782011a47737c1787b697de1fa35c12b1eba72a3a3ad6226e2.25d8d06fb0679146a3ed2a3463e3585380bff882fe6e1ebc497196e40dbbd7fa\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv1/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-f12cafd0ad8e3c46.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv1/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-75323d02a8145db5.arrow\n",
      "loading configuration file ./bert/bert_cv1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./bert/bert_cv1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading weights file ./bert/bert_cv1/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n",
      "\n",
      "Trained Model exists, Load model from ./bert/bert_cv1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./bert/bert_cv1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Trained Model from ./bert/bert_cv1 completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 448\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of validation data started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of validation data completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv2/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': {'precision': 0.4034090909090909, 'recall': 0.4771505376344086, 'f1': 0.4371921182266009, 'number': 744}, 'anner': {'precision': 0.16666666666666666, 'recall': 0.043478260869565216, 'f1': 0.06896551724137931, 'number': 23}, 'ccompanyment': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}, 'easure': {'precision': 0.3409090909090909, 'recall': 0.46875, 'f1': 0.39473684210526316, 'number': 32}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 19}, 'erb': {'precision': 0.687007874015748, 'recall': 0.77728285077951, 'f1': 0.7293625914315569, 'number': 449}, 'gent': {'precision': 0.3924050632911392, 'recall': 0.4696969696969697, 'f1': 0.42758620689655175, 'number': 66}, 'ime': {'precision': 0.24444444444444444, 'recall': 0.3235294117647059, 'f1': 0.27848101265822783, 'number': 34}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}, 'ocation': {'precision': 0.25773195876288657, 'recall': 0.33783783783783783, 'f1': 0.29239766081871343, 'number': 74}, 'xperiencer': {'precision': 0.5265822784810127, 'recall': 0.4781609195402299, 'f1': 0.5012048192771086, 'number': 435}, 'overall_precision': 0.48207364341085274, 'overall_recall': 0.5264550264550265, 'overall_f1': 0.5032878098128477, 'overall_accuracy': 0.720416018344116}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Accompanyment     0.8500    0.3617    0.5075        47\n",
      "        Agent     0.5243    0.5347    0.5294       101\n",
      "   Benefactor     0.0000    0.0000    0.0000         6\n",
      "  Experiencer     0.5743    0.4793    0.5225       121\n",
      "   Instrument     0.0000    0.0000    0.0000        35\n",
      "     Location     0.5784    0.5632    0.5707       190\n",
      "       Manner     1.0000    0.1000    0.1818        70\n",
      "      Measure     0.5976    0.6950    0.6426       141\n",
      "       Object     0.6983    0.7120    0.7051       816\n",
      "         Time     0.5652    0.6741    0.6149       135\n",
      "\n",
      "    micro avg     0.6440    0.6095    0.6263      1662\n",
      "    macro avg     0.5388    0.4120    0.4274      1662\n",
      " weighted avg     0.6454    0.6095    0.6081      1662\n",
      "  samples avg     0.2449    0.2449    0.2449      1662\n",
      "\n",
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  cv2\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_cv2\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14241502f722408c8a8a102feb53ebea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1790\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 448\n",
      "    })\n",
      "})\n",
      "Sample  :  ['ฝึก', 'ให้', 'ลูก', 'กุ้ง', 'กิน', 'อาหาร', 'ไข่ตุ๋น', 'ก่อน']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/vocab.txt from cache at /home/yoyo/.cache/huggingface/transformers/2c236d2bea3780922dffc22e3b3149292a1a9a9b1b7d3a150564cab2e141c43d.9bc9bc72e9459be65d9c850352dbf9415c2a73580d3c52ad2356af3657bafc66\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer_config.json from cache at /home/yoyo/.cache/huggingface/transformers/f321b63387f2d3782011a47737c1787b697de1fa35c12b1eba72a3a3ad6226e2.25d8d06fb0679146a3ed2a3463e3585380bff882fe6e1ebc497196e40dbbd7fa\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv2/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-5f358665f63f98b8.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv2/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-37b3fde74f1792d8.arrow\n",
      "loading configuration file ./bert/bert_cv2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./bert/bert_cv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading weights file ./bert/bert_cv2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n",
      "\n",
      "Trained Model exists, Load model from ./bert/bert_cv2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./bert/bert_cv2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Trained Model from ./bert/bert_cv2 completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 448\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of validation data started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of validation data completed ...\n",
      "\n",
      "{'O': {'precision': 0.3882476390346275, 'recall': 0.4648241206030151, 'f1': 0.4230989136649514, 'number': 796}, 'anner': {'precision': 0.25, 'recall': 0.047619047619047616, 'f1': 0.08, 'number': 21}, 'ccompanyment': {'precision': 0.1, 'recall': 0.1111111111111111, 'f1': 0.10526315789473685, 'number': 9}, 'easure': {'precision': 0.18571428571428572, 'recall': 0.2653061224489796, 'f1': 0.21848739495798322, 'number': 49}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 23}, 'erb': {'precision': 0.6038461538461538, 'recall': 0.7008928571428571, 'f1': 0.6487603305785123, 'number': 448}, 'gent': {'precision': 0.46534653465346537, 'recall': 0.4845360824742268, 'f1': 0.47474747474747475, 'number': 97}, 'ime': {'precision': 0.26666666666666666, 'recall': 0.35294117647058826, 'f1': 0.3037974683544304, 'number': 34}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 11}, 'ocation': {'precision': 0.2111111111111111, 'recall': 0.2835820895522388, 'f1': 0.24203821656050956, 'number': 67}, 'xperiencer': {'precision': 0.35127478753541075, 'recall': 0.36151603498542273, 'f1': 0.3563218390804598, 'number': 343}, 'overall_precision': 0.41985088536812676, 'overall_recall': 0.4747102212855637, 'overall_f1': 0.4455984174085064, 'overall_accuracy': 0.7094307561597282}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "vi ['ดอก', 'เห็ด', 'แห้ง', 'ฝ่อ/vi_'] ['ด', '##อก', 'เ', '##ห', '##็', '##ด', 'แ', '##ห', '##้', '##ง', 'ฝ', '##่อ', '/', 'vi', '_']\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unexpected token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/fasttrack/semantic_role_classification/sem_role_transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unexpected token'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgt_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'[UNK]'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mpred_lbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Unexpected token"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv3/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  cv3\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_cv3\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c1d77dd1f545a0bdc3d5944c6fbdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1791\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 447\n",
      "    })\n",
      "})\n",
      "Sample  :  ['จะ', 'กิน', 'ไร', 'จน', 'มี', 'อายุ', 'ได้', '_', '7', '_', 'วัน']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/vocab.txt from cache at /home/yoyo/.cache/huggingface/transformers/2c236d2bea3780922dffc22e3b3149292a1a9a9b1b7d3a150564cab2e141c43d.9bc9bc72e9459be65d9c850352dbf9415c2a73580d3c52ad2356af3657bafc66\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer_config.json from cache at /home/yoyo/.cache/huggingface/transformers/f321b63387f2d3782011a47737c1787b697de1fa35c12b1eba72a3a3ad6226e2.25d8d06fb0679146a3ed2a3463e3585380bff882fe6e1ebc497196e40dbbd7fa\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv3/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-2f816106439518ec.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv3/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-324255f0588e4b48.arrow\n",
      "loading configuration file ./bert/bert_cv3/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./bert/bert_cv3\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading weights file ./bert/bert_cv3/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n",
      "\n",
      "Trained Model exists, Load model from ./bert/bert_cv3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./bert/bert_cv3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Trained Model from ./bert/bert_cv3 completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of validation data started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of validation data completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv4/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': {'precision': 0.36438923395445133, 'recall': 0.46194225721784776, 'f1': 0.4074074074074074, 'number': 762}, 'anner': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 25}, 'ccompanyment': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}, 'easure': {'precision': 0.1836734693877551, 'recall': 0.20930232558139536, 'f1': 0.1956521739130435, 'number': 43}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 40}, 'erb': {'precision': 0.6220472440944882, 'recall': 0.7022222222222222, 'f1': 0.6597077244258873, 'number': 450}, 'gent': {'precision': 0.36666666666666664, 'recall': 0.44, 'f1': 0.4, 'number': 75}, 'ime': {'precision': 0.2037037037037037, 'recall': 0.2972972972972973, 'f1': 0.2417582417582418, 'number': 37}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}, 'ocation': {'precision': 0.14705882352941177, 'recall': 0.18518518518518517, 'f1': 0.1639344262295082, 'number': 81}, 'xperiencer': {'precision': 0.3657331136738056, 'recall': 0.47334754797441364, 'f1': 0.412639405204461, 'number': 469}, 'overall_precision': 0.3998330550918197, 'overall_recall': 0.48020050125313285, 'overall_f1': 0.43634707355955366, 'overall_accuracy': 0.6566398775353999}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Accompanyment     0.3000    0.1250    0.1765        24\n",
      "        Agent     0.6261    0.4557    0.5275       158\n",
      "   Benefactor     0.0000    0.0000    0.0000         9\n",
      "  Experiencer     0.3913    0.4809    0.4315       131\n",
      "   Instrument     0.0000    0.0000    0.0000        26\n",
      "     Location     0.4890    0.3904    0.4341       228\n",
      "       Manner     0.0000    0.0000    0.0000        61\n",
      "      Measure     0.5724    0.4171    0.4826       199\n",
      "       Object     0.6877    0.5553    0.6144       904\n",
      "         Time     0.5471    0.8243    0.6577       148\n",
      "\n",
      "    micro avg     0.5964    0.4947    0.5408      1888\n",
      "    macro avg     0.3614    0.3249    0.3324      1888\n",
      " weighted avg     0.5749    0.4947    0.5254      1888\n",
      "  samples avg     0.2121    0.2121    0.2121      1888\n",
      "\n",
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  cv4\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_cv4\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376922ef81054784b4b678cabf694b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1791\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 447\n",
      "    })\n",
      "})\n",
      "Sample  :  ['ป้องกัน', 'หนู', 'นา', 'กัด', 'กิน', 'ต้น', 'ข้าว']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/vocab.txt from cache at /home/yoyo/.cache/huggingface/transformers/2c236d2bea3780922dffc22e3b3149292a1a9a9b1b7d3a150564cab2e141c43d.9bc9bc72e9459be65d9c850352dbf9415c2a73580d3c52ad2356af3657bafc66\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer_config.json from cache at /home/yoyo/.cache/huggingface/transformers/f321b63387f2d3782011a47737c1787b697de1fa35c12b1eba72a3a3ad6226e2.25d8d06fb0679146a3ed2a3463e3585380bff882fe6e1ebc497196e40dbbd7fa\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv4/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-20c0b5a3dab1d0cd.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/cv4/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-43e1366716f30deb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/pytorch_model.bin from cache at /home/yoyo/.cache/huggingface/transformers/9c9e12d5c35f140665330c2a7cc722a578d43eaba836c9d0882fa0731950a451.a5cf14bbdd3fa3aa2bb9c071f2fd4614f82e3caae4573bca89ca926fe6bd6b6d\n",
      "Some weights of the model checkpoint at Geotrend/bert-base-th-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at Geotrend/bert-base-th-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 1791\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1344' max='1344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1344/1344 01:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.245600</td>\n",
       "      <td>0.991992</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.338685</td>\n",
       "      <td>0.333498</td>\n",
       "      <td>0.639525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.835200</td>\n",
       "      <td>0.886199</td>\n",
       "      <td>0.416588</td>\n",
       "      <td>0.443552</td>\n",
       "      <td>0.429648</td>\n",
       "      <td>0.680946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.891897</td>\n",
       "      <td>0.444692</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>0.470838</td>\n",
       "      <td>0.701545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./bert/checkpoint-448\n",
      "Configuration saved in ./bert/checkpoint-448/config.json\n",
      "Model weights saved in ./bert/checkpoint-448/pytorch_model.bin\n",
      "tokenizer config file saved in ./bert/checkpoint-448/tokenizer_config.json\n",
      "Special tokens file saved in ./bert/checkpoint-448/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./bert/checkpoint-896\n",
      "Configuration saved in ./bert/checkpoint-896/config.json\n",
      "Model weights saved in ./bert/checkpoint-896/pytorch_model.bin\n",
      "tokenizer config file saved in ./bert/checkpoint-896/tokenizer_config.json\n",
      "Special tokens file saved in ./bert/checkpoint-896/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./bert/checkpoint-1344\n",
      "Configuration saved in ./bert/checkpoint-1344/config.json\n",
      "Model weights saved in ./bert/checkpoint-1344/pytorch_model.bin\n",
      "tokenizer config file saved in ./bert/checkpoint-1344/tokenizer_config.json\n",
      "Special tokens file saved in ./bert/checkpoint-1344/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./bert/checkpoint-896 (score: 0.886198878288269).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model completed ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='224' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./bert/bert_cv4\n",
      "Configuration saved in ./bert/bert_cv4/config.json\n",
      "Model weights saved in ./bert/bert_cv4/pytorch_model.bin\n",
      "tokenizer config file saved in ./bert/bert_cv4/tokenizer_config.json\n",
      "Special tokens file saved in ./bert/bert_cv4/special_tokens_map.json\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save Trained Model Weights at ./bert/bert_cv4 ...\n",
      "\n",
      "\n",
      "Prediction of validation data started ...\n",
      "Prediction of validation data completed ...\n",
      "\n",
      "{'O': {'precision': 0.3352601156069364, 'recall': 0.45253576072821844, 'f1': 0.38516878804648585, 'number': 769}, 'anner': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}, 'ccompanyment': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 10}, 'easure': {'precision': 0.2753623188405797, 'recall': 0.36538461538461536, 'f1': 0.3140495867768595, 'number': 52}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}, 'erb': {'precision': 0.6252676659528907, 'recall': 0.6503340757238307, 'f1': 0.6375545851528385, 'number': 449}, 'gent': {'precision': 0.3291139240506329, 'recall': 0.32098765432098764, 'f1': 0.32499999999999996, 'number': 81}, 'ime': {'precision': 0.23529411764705882, 'recall': 0.34285714285714286, 'f1': 0.2790697674418605, 'number': 35}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}, 'ocation': {'precision': 0.14, 'recall': 0.2153846153846154, 'f1': 0.1696969696969697, 'number': 65}, 'xperiencer': {'precision': 0.5598705501618123, 'recall': 0.34808853118712274, 'f1': 0.4292803970223325, 'number': 497}, 'overall_precision': 0.41658812441093307, 'overall_recall': 0.4435524335173106, 'overall_f1': 0.42964763061968403, 'overall_accuracy': 0.6809463392790507}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "ก ['ฟักทอง', 'แก่', 'จัด', '2', '_', 'ก.ก.'] ['ฟ', '##ัก', '##ท', '##อง', 'แ', '##ก', '##่', 'จ', '##ัด', '2', '_', 'ก', '.', 'ก', '.']\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unexpected token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/fasttrack/semantic_role_classification/sem_role_transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unexpected token'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgt_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'[UNK]'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mpred_lbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Unexpected token"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/oov/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  oov\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_oov\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7222fb341138407fbed2d7004efc7525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1807\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 447\n",
      "    })\n",
      "})\n",
      "Sample  :  ['จะ', 'กิน', 'ไร', 'จน', 'มี', 'อายุ', 'ได้', '_', '7', '_', 'วัน']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/vocab.txt from cache at /home/yoyo/.cache/huggingface/transformers/2c236d2bea3780922dffc22e3b3149292a1a9a9b1b7d3a150564cab2e141c43d.9bc9bc72e9459be65d9c850352dbf9415c2a73580d3c52ad2356af3657bafc66\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer_config.json from cache at /home/yoyo/.cache/huggingface/transformers/f321b63387f2d3782011a47737c1787b697de1fa35c12b1eba72a3a3ad6226e2.25d8d06fb0679146a3ed2a3463e3585380bff882fe6e1ebc497196e40dbbd7fa\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/oov/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-44f6341f97305f26.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/oov/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-fad69956109c147d.arrow\n",
      "loading configuration file ./bert/bert_oov/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./bert/bert_oov\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading weights file ./bert/bert_oov/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n",
      "\n",
      "Trained Model exists, Load model from ./bert/bert_oov.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./bert/bert_oov.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Trained Model from ./bert/bert_oov completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 447\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of validation data started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of validation data completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Reusing dataset sem_role_bank (/home/yoyo/.cache/huggingface/datasets/sem_role_bank/std/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': {'precision': 0.46817691477885653, 'recall': 0.5695538057742782, 'f1': 0.5139135583185316, 'number': 762}, 'anner': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 25}, 'ccompanyment': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}, 'easure': {'precision': 0.43137254901960786, 'recall': 0.5116279069767442, 'f1': 0.46808510638297873, 'number': 43}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 40}, 'erb': {'precision': 0.7238493723849372, 'recall': 0.7688888888888888, 'f1': 0.7456896551724138, 'number': 450}, 'gent': {'precision': 0.4077669902912621, 'recall': 0.56, 'f1': 0.47191011235955055, 'number': 75}, 'ime': {'precision': 0.3111111111111111, 'recall': 0.3783783783783784, 'f1': 0.34146341463414637, 'number': 37}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}, 'ocation': {'precision': 0.32038834951456313, 'recall': 0.4074074074074074, 'f1': 0.3586956521739131, 'number': 81}, 'xperiencer': {'precision': 0.6090712742980562, 'recall': 0.6012793176972282, 'f1': 0.6051502145922748, 'number': 469}, 'overall_precision': 0.5398067188219052, 'overall_recall': 0.58796992481203, 'overall_f1': 0.5628598848368522, 'overall_accuracy': 0.7662456946039036}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Accompanyment     0.7778    0.2917    0.4242        24\n",
      "        Agent     0.7083    0.6456    0.6755       158\n",
      "   Benefactor     0.0000    0.0000    0.0000         9\n",
      "  Experiencer     0.5952    0.5725    0.5837       131\n",
      "   Instrument     0.0000    0.0000    0.0000        26\n",
      "     Location     0.6724    0.6842    0.6783       228\n",
      "       Manner     0.0000    0.0000    0.0000        61\n",
      "      Measure     0.6934    0.7387    0.7153       199\n",
      "       Object     0.7801    0.7102    0.7435       904\n",
      "         Time     0.7097    0.8919    0.7904       148\n",
      "\n",
      "    micro avg     0.7281    0.6679    0.6967      1888\n",
      "    macro avg     0.4937    0.4535    0.4611      1888\n",
      " weighted avg     0.6939    0.6679    0.6777      1888\n",
      "  samples avg     0.2863    0.2863    0.2863      1888\n",
      "\n",
      "Hugging Face Transformers Version : 4.15.0\n",
      "Hugging Face Tokenizers Version : 0.10.3\n",
      "=====================================\n",
      "CONFIG_NAME \t\t=  std\n",
      "MODEL_PATH \t\t=  ./bert/\n",
      "MODEL_NAME \t\t=  bert_std\n",
      "=========  Hyperparameters  =========\n",
      "model_checkpoint \t=  Geotrend/bert-base-th-cased\n",
      "batch_size \t\t=  4\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56be8cb475af446ca9762da625f6a8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 1790\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'role_tags'],\n",
      "        num_rows: 448\n",
      "    })\n",
      "})\n",
      "Sample  :  ['สามารถ', 'ขาย', 'ผลผลิต', 'หมด', 'ก่อน', 'เที่ยง']\n",
      "Label List :  ['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time', 'Verb', 'Z-O']\n",
      "\n",
      "Tokenization started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/vocab.txt from cache at /home/yoyo/.cache/huggingface/transformers/2c236d2bea3780922dffc22e3b3149292a1a9a9b1b7d3a150564cab2e141c43d.9bc9bc72e9459be65d9c850352dbf9415c2a73580d3c52ad2356af3657bafc66\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/tokenizer_config.json from cache at /home/yoyo/.cache/huggingface/transformers/f321b63387f2d3782011a47737c1787b697de1fa35c12b1eba72a3a3ad6226e2.25d8d06fb0679146a3ed2a3463e3585380bff882fe6e1ebc497196e40dbbd7fa\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Geotrend/bert-base-th-cased/resolve/main/config.json from cache at /home/yoyo/.cache/huggingface/transformers/9477b06f479be44e0141c92590deccd3b298ce76ef3db3841c1063e8cb0aa7fb.d10eb9efa3f4e007af546ad48f260d9994aa6dd3246c106ada56e27a99779e7e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Geotrend/bert-base-th-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/std/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-e076fe9b011a2b98.arrow\n",
      "Loading cached processed dataset at /home/yoyo/.cache/huggingface/datasets/sem_role_bank/std/1.0.0/0c634fc12d7a4053678206c059870924992d934fd51018d1ac4d8227d3472504/cache-2212b843159a27f0.arrow\n",
      "loading configuration file ./bert/bert_std/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./bert/bert_std\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8506\n",
      "}\n",
      "\n",
      "loading weights file ./bert/bert_std/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed ...\n",
      "\n",
      "\n",
      "Trained Model exists, Load model from ./bert/bert_std.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./bert/bert_std.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Trained Model from ./bert/bert_std completed ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: role_tags, id, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 448\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of validation data started ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Z-O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Verb seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Object seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Manner seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Measure seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Experiencer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Accompanyment seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Benefactor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Instrument seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of validation data completed ...\n",
      "\n",
      "{'O': {'precision': 0.3857566765578635, 'recall': 0.47158403869407495, 'f1': 0.4243743199129489, 'number': 827}, 'anner': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 25}, 'ccompanyment': {'precision': 0.05555555555555555, 'recall': 0.1111111111111111, 'f1': 0.07407407407407407, 'number': 9}, 'easure': {'precision': 0.19718309859154928, 'recall': 0.2916666666666667, 'f1': 0.2352941176470588, 'number': 48}, 'enefactor': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 35}, 'erb': {'precision': 0.6378269617706237, 'recall': 0.7028824833702882, 'f1': 0.6687763713080168, 'number': 451}, 'gent': {'precision': 0.34, 'recall': 0.4358974358974359, 'f1': 0.38202247191011235, 'number': 78}, 'ime': {'precision': 0.24561403508771928, 'recall': 0.3111111111111111, 'f1': 0.27450980392156865, 'number': 45}, 'nstrument': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}, 'ocation': {'precision': 0.3111111111111111, 'recall': 0.3783783783783784, 'f1': 0.34146341463414637, 'number': 74}, 'xperiencer': {'precision': 0.4258188824662813, 'recall': 0.4857142857142857, 'f1': 0.4537987679671458, 'number': 455}, 'overall_precision': 0.43032094594594594, 'overall_recall': 0.4958637469586375, 'overall_f1': 0.46077323083879723, 'overall_accuracy': 0.7112129499593466}\n",
      "Align labels to original tokens ...\n",
      "\n",
      "['Accompanyment', 'Agent', 'Benefactor', 'Experiencer', 'Instrument', 'Location', 'Manner', 'Measure', 'Object', 'Time']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Accompanyment     0.8261    0.5000    0.6230        76\n",
      "        Agent     0.5000    0.4474    0.4722       152\n",
      "   Benefactor     0.0000    0.0000    0.0000         9\n",
      "  Experiencer     0.4098    0.4310    0.4202       116\n",
      "   Instrument     0.0000    0.0000    0.0000        16\n",
      "     Location     0.5056    0.5796    0.5401       157\n",
      "       Manner     1.0000    0.0824    0.1522        85\n",
      "      Measure     0.6608    0.6356    0.6479       236\n",
      "       Object     0.7338    0.6597    0.6948       961\n",
      "         Time     0.5833    0.6863    0.6306       153\n",
      "\n",
      "    micro avg     0.6487    0.5829    0.6140      1961\n",
      "    macro avg     0.5219    0.4022    0.4181      1961\n",
      " weighted avg     0.6635    0.5829    0.6031      1961\n",
      "  samples avg     0.2455    0.2455    0.2455      1961\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yoyo/anaconda3/envs/bert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for CONFIG_NAME in ['cv0', 'cv1', 'cv2', 'cv3', 'cv4', 'oov' ,'std']:\n",
    "    MODEL_NAME = f\"bert_{CONFIG_NAME}\"\n",
    "    %run sem_role_transformer.py --config_name=$CONFIG_NAME --model_path=$MODEL_PATH --model_name=$MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a247cbbb-2c71-457c-a95b-494cec86f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run sem_role_transformer.py --config_name=$CONFIG_NAME --model_path=$MODEL_PATH --model_name=$MODEL_NAME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
